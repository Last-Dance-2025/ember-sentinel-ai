import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

# --- 1. ì„¤ì • ë³€ìˆ˜ ---
# âš ï¸ ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.
DATASET_ROOT = 'FASDD_CV/yolo_format'
LABELS_DIR = os.path.join(DATASET_ROOT, 'labels')
IMAGE_DIR = os.path.join(DATASET_ROOT, 'images')

# data.yamlì˜ í´ë˜ìŠ¤ ì´ë¦„ê³¼ ìˆœì„œì— ë§ì¶¥ë‹ˆë‹¤.
CLASS_NAMES = ['fire', 'smoke']
NUM_CLASSES = len(CLASS_NAMES)
# --------------------

def collect_all_files():
    """ëª¨ë“  ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œì™€ ì „ì²´ ì´ë¯¸ì§€ ìˆ˜ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    
    # âš ï¸ test ë¶„í•  ì œì™¸
    splits_to_analyze = ['train', 'val']
    
    all_label_paths = []
    all_image_count = 0
    
    print("--- íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ ì¤‘ ---")
    
    for split_dir in splits_to_analyze:
        labels_path = os.path.join(LABELS_DIR, split_dir)
        images_path = os.path.join(IMAGE_DIR, split_dir)
        
        # ë ˆì´ë¸” íŒŒì¼ ìˆ˜ì§‘
        if os.path.exists(labels_path):
            label_files = [os.path.join(labels_path, f) for f in os.listdir(labels_path) if f.endswith('.txt')]
            all_label_paths.extend(label_files)
        
        # ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì§‘ (ì´ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°)
        if os.path.exists(images_path):
            all_image_count += len([f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
            
    return all_label_paths, all_image_count

def analyze_yolo_labels_combined(all_label_paths, total_image_count):
    """
    ìˆ˜ì§‘ëœ ëª¨ë“  ë ˆì´ë¸” íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ í†µí•©ëœ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    
    all_class_counts = np.zeros(NUM_CLASSES, dtype=int)
    all_box_widths = []
    all_box_heights = []
    all_box_areas = []
    all_aspect_ratios = []
    
    total_annotations = 0
    total_labeled_images = 0
    
    # tqdmì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ ë ˆì´ë¸” íŒŒì¼ ì²˜ë¦¬ ì§„í–‰ë¥  í‘œì‹œ
    for file_path in tqdm(all_label_paths, desc=f"ë ˆì´ë¸” ë¶„ì„ ë° ë°ì´í„° ì¶”ì¶œ ì¤‘"):
        try:
            with open(file_path, 'r') as f:
                lines = f.readlines()
            
            if not lines:
                continue
                
            total_labeled_images += 1
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    # YOLO í¬ë§·: [class_id, center_x, center_y, width, height] (ëª¨ë‘ ì •ê·œí™”ëœ ê°’ 0~1)
                    width = float(parts[3])
                    height = float(parts[4])
                    
                    if 0 <= class_id < NUM_CLASSES:
                        all_class_counts[class_id] += 1
                        total_annotations += 1
                        
                        all_box_widths.append(width)
                        all_box_heights.append(height)
                        all_box_areas.append(width * height)
                        # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ì‘ì€ ê°’ ì¶”ê°€
                        all_aspect_ratios.append(width / (height + 1e-6)) 
                        
        except Exception as e:
            # print(f"ê²½ê³ : {file_path} íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            pass
            
    return {
        'total_image_count': total_image_count,
        'total_annotations': total_annotations,
        'labeled_images': total_labeled_images,
        'class_counts': all_class_counts,
        'widths': all_box_widths,
        'heights': all_box_heights,
        'areas': all_box_areas,
        'aspect_ratios': all_aspect_ratios
    }

def print_combined_summary(analysis_data):
    """í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤."""
    
    labeled_images = analysis_data['labeled_images']
    image_count = analysis_data['total_image_count']
    
    print("\n" + "=" * 60)
    print("## ğŸ“‹ Training Dataset Summary")
    print("=" * 60)
    print(f"Total Images: {image_count}")
    print(f"Labeled Images: {labeled_images} ({labeled_images / image_count * 100:.2f}%)")
    print(f"Total Annotations: {analysis_data['total_annotations']}")

    # í´ë˜ìŠ¤ ë¶„í¬ í…Œì´ë¸”
    df_class = pd.DataFrame({
        'Class': CLASS_NAMES,
        'Count': analysis_data['class_counts'],
        'Percentage': analysis_data['class_counts'] / analysis_data['total_annotations'] * 100
    })
    print("\n### Class Distribution:")
    print(df_class.to_markdown(index=False, floatfmt=".2f"))

# â­ï¸ plot_distribution í•¨ìˆ˜ ìˆ˜ì •: ì œëª©/ë ˆì´ë¸”ì´ ëª¨ë‘ ì˜ì–´ë¡œ ë³€ê²½ë¨
def plot_distribution(data, title, xlabel, ylabel, bins=50, log_scale=False, filename=None):
    """íˆìŠ¤í† ê·¸ë¨ì„ ê·¸ë ¤ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    
    plt.figure(figsize=(10, 6))
    
    # ì¢…íš¡ë¹„ ë°ì´í„° í´ë¦¬í•‘
    if 'Aspect Ratio' in title:
        data = np.clip(data, 0, 10) 
        bins = 100
        
    plt.hist(data, bins=bins, log=log_scale, color='indianred', edgecolor='black')
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel) # â­ï¸ ylabelë„ ë™ì ìœ¼ë¡œ ì„¤ì •
    plt.grid(axis='y', alpha=0.75)
    
    # ê·¸ë¦¼ ì €ì¥
    plot_dir = 'eda_results'
    os.makedirs(plot_dir, exist_ok=True)
    if filename:
        plt.savefig(os.path.join(plot_dir, filename))
        print(f"âœ… Plot saved: {os.path.join(plot_dir, filename)}")
    plt.close()

def perform_eda_combined():
    """ë©”ì¸ í†µí•© EDA ì‹¤í–‰ í•¨ìˆ˜."""
    
    print(f"Dataset analysis path: {DATASET_ROOT}")
    
    # 1. ëª¨ë“  ë ˆì´ë¸” íŒŒì¼ ê²½ë¡œì™€ ì´ ì´ë¯¸ì§€ ìˆ˜ ìˆ˜ì§‘
    all_label_paths, total_image_count = collect_all_files()
    
    if not all_label_paths:
        print("Error: No label files found in train or val splits.")
        return

    # 2. í†µí•© ë¶„ì„ ì‹¤í–‰
    analysis_data = analyze_yolo_labels_combined(all_label_paths, total_image_count)
    
    # 3. ìš”ì•½ ì¶œë ¥
    print_combined_summary(analysis_data)
        
    print("\n" + "=" * 50)
    print("## ğŸ“ˆ Training Data Distribution Analysis (Plots)")
    print("=" * 50)

    # 4. ì‹œê°í™” ë¶„ì„ ë° íŒŒì¼ ì €ì¥ (ëª¨ë‘ ì˜ë¬¸ìœ¼ë¡œ ë³€ê²½)
    
    # A. ê°ì²´ í¬ê¸° ë¶„í¬ (ì •ê·œí™”ëœ Area)
    plot_distribution(
        analysis_data['areas'], 
        "Object Area Distribution (Normalized, Log Scale)", 
        "Normalized Area (W * H)", 
        "Frequency (Log Scale)", # â­ï¸ Yì¶• ë ˆì´ë¸” ë³€ê²½
        bins=100, 
        log_scale=True,
        filename="1_area_distribution.png"
    )
    
    # B. ì¢…íš¡ë¹„ ë¶„í¬ (Aspect Ratio)
    plot_distribution(
        analysis_data['aspect_ratios'], 
        "Object Aspect Ratio Distribution", 
        "Aspect Ratio (W / H)", 
        "Frequency",
        bins=100,
        filename="2_aspect_ratio_distribution.png"
    )

    # C. ê°ì²´ Width/Height ë¶„í¬
    plot_distribution(
        analysis_data['widths'], 
        "Normalized Object Width Distribution", 
        "Normalized Width", 
        "Frequency",
        bins=50,
        filename="3_normalized_width_distribution.png"
    )
    plot_distribution(
        analysis_data['heights'], 
        "Normalized Object Height Distribution", 
        "Normalized Height", 
        "Frequency",
        bins=50,
        filename="4_normalized_height_distribution.png"
    )
    
    print("\nAnalysis complete. Check the 'eda_results' folder for plots.")
    print("--- EDA.py finished ---")


if __name__ == "__main__":
    perform_eda_combined()